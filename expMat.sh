python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_a --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0001 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 38 --hidden 64 --relu True --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer SDG && echo "Done month_agg_a!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_b --save-agent --reward-coef 1.0 --proj-coef 1.0 --learning-rate 0.001 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer SDG && echo "Done month_agg_b!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_c --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 1.0 --logstd -1.5 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std False --optimizer Adam && echo "Done month_agg_c!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_d --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.03 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 2 --num-minibatches 1 --lax-coef 0.0 --logstd -2.5 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_d!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_e --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0001 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -1.5 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_e!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_f --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 10.0 --logstd -1.0 --n-state 38 --hidden 128 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std False --optimizer Adam && echo "Done month_agg_f!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_g --save-agent --reward-coef 1.0 --proj-coef 100.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 38 --hidden 256 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_g!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_h --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 20 --num-minibatches 1 --lax-coef 0.0 --logstd -0.1 --n-state 38 --hidden 64 --relu True --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_h!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_i --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -1.0 --n-state 38 --hidden 64 --relu False --no-safety True --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_i!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_j --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd 1.5 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state True --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_j!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_k --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 64 --relu False --no-safety False --norm-state False --without-perc True --norm-reward False --reset-std False --optimizer Adam && echo "Done month_agg_k!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_l --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd 0.0 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward True --reset-std True --optimizer Adam && echo "Done month_agg_l!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_m --save-agent --reward-coef 0.001 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd 0.1 --n-state 38 --hidden 64 --relu False --no-safety False --norm-state False --without-perc False --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_m!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_n --save-agent --reward-coef 100.0 --proj-coef 0.0 --learning-rate 0.0001 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 8 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 128 --relu True --no-safety False --norm-state False --without-perc True --norm-reward False --reset-std False --optimizer Adam && echo "Done month_agg_n!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_o --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.01 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 128 --relu False --no-safety False --norm-state False --without-perc True --norm-reward False --reset-std False --optimizer SDG && echo "Done month_agg_o!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_p --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 48 --anneal-lr True  --update-epochs 20 --num-minibatches 1 --lax-coef 0.1 --logstd -2.0 --n-state 18 --hidden 64 --relu False --no-safety False --norm-state False --without-perc True --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_p!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_q --save-agent --reward-coef 1.0 --proj-coef 10.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 2 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 64 --relu False --no-safety False --norm-state False --without-perc True --norm-reward True --reset-std True --optimizer Adam && echo "Done month_agg_q!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_r --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 8 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 1.0 --logstd -2.0 --n-state 18 --hidden 256 --relu False --no-safety False --norm-state True --without-perc True --norm-reward True --reset-std False --optimizer Adam && echo "Done month_agg_r!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_s --save-agent --reward-coef 1.0 --proj-coef 0.1 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 64 --relu False --no-safety True --norm-state False --without-perc True --norm-reward False --reset-std False --optimizer Adam && echo "Done month_agg_s!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_t --save-agent --reward-coef 1.0 --proj-coef 0.1 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.1 --logstd -2.0 --n-state 18 --hidden 512 --relu False --no-safety False --norm-state False --without-perc True --norm-reward False --reset-std True --optimizer Adam && echo "Done month_agg_t!" &
python3 RunRLChargeWorld.py --agent PPO-agg --save-name month_agg_u --save-agent --reward-coef 1.0 --proj-coef 0.0 --learning-rate 0.0003 --file-price df_price_2019_pad.csv --years 50 --num-steps 24 --anneal-lr True  --update-epochs 10 --num-minibatches 1 --lax-coef 0.0 --logstd -2.0 --n-state 18 --hidden 64 --relu False --no-safety False --norm-state False --without-perc True --norm-reward True --reset-std True --optimizer Adam && echo "Done month_agg_u!" &
